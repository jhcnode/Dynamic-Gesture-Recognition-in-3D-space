{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_DIM=100\n",
    "NUM_LABELS\t\t= 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def selu(x, name):\n",
    "    with ops.name_scope('elu') as scope:\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        return scale*tf.where(x>=0.0, x, alpha*tf.nn.elu(x,name))\n",
    "\n",
    "\n",
    "# placeholder is used for feeding data.\n",
    "x = tf.placeholder(tf.float32, shape=[None, NUM_DIM], name = 'x') # none represents variable length of dimension. 784 is the dimension of MNIST data.\n",
    "y_target = tf.placeholder(tf.float32, shape=[None, NUM_LABELS], name = 'y_target') # shape argument is optional, but this is useful to debug.\n",
    "\n",
    "\n",
    "# reshape input data\n",
    "x_data = tf.reshape(x, [-1,NUM_DIM], name=\"x_data\")\n",
    "\n",
    "# Build a fully connected layer\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([NUM_DIM, 1024],stddev=np.sqrt(1/NUM_DIM)), name = 'W_fc1')\n",
    "b_fc1 = tf.Variable(tf.random_normal([1024],stddev=0), name = 'b_fc1')\n",
    "h_fc1 = selu(tf.matmul(x_data, W_fc1) + b_fc1, name=\"h_fc1\")\n",
    "\n",
    "shape = h_fc1.get_shape().as_list()\n",
    "flat_num= shape[1]\n",
    "\n",
    "# Build a fully connected layer\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([flat_num, 512], stddev=np.sqrt(1/flat_num)), name = 'W_fc2')\n",
    "b_fc2 = tf.Variable(tf.random_normal([512],stddev=0), name = 'b_fc2')\n",
    "h_fc2 = selu(tf.matmul(h_fc1, W_fc2) + b_fc2, name=\"h_fc2\")\n",
    "\n",
    "shape = h_fc2.get_shape().as_list()\n",
    "flat_num= shape[1]\n",
    "\n",
    "# Build a fully connected layer\n",
    "W_fc3 = tf.Variable(tf.truncated_normal([flat_num, 256], stddev=np.sqrt(1/flat_num)), name = 'W_fc3')\n",
    "b_fc3 = tf.Variable(tf.random_normal([256],stddev=0), name = 'b_fc3')\n",
    "h_fc3 = selu(tf.matmul(h_fc2, W_fc3) + b_fc3, name=\"h_fc3\")\n",
    "\n",
    "shape = h_fc3.get_shape().as_list()\n",
    "flat_num= shape[1]\n",
    "\n",
    "# Build a fully connected layer\n",
    "W_fc4 = tf.Variable(tf.truncated_normal([flat_num, 128], stddev=np.sqrt(1/flat_num)), name = 'W_fc4')\n",
    "b_fc4 = tf.Variable(tf.random_normal([128],stddev=0), name = 'b_fc4')\n",
    "h_fc4 = selu(tf.matmul(h_fc3, W_fc4) + b_fc4, name=\"h_fc4\")\n",
    "\n",
    "shape = h_fc4.get_shape().as_list()\n",
    "flat_num= shape[1]\n",
    "\n",
    "\n",
    "W_fc5 = tf.Variable(tf.random_normal([flat_num, 64], stddev=np.sqrt(1/flat_num)), name = 'W_fc5')\n",
    "b_fc5 = tf.Variable(tf.random_normal([64],stddev=0), name = 'b_fc5')\n",
    "h_fc5 =selu(tf.matmul(h_fc4, W_fc5) + b_fc5, name=\"h_fc5\")\n",
    "\n",
    "shape = h_fc5.get_shape().as_list()\n",
    "flat_num= shape[1]\n",
    "\n",
    "W_fc6 = tf.Variable(tf.random_normal([flat_num, NUM_LABELS], stddev=np.sqrt(1/flat_num)), name = 'W_fc6')\n",
    "b_fc6 = tf.Variable(tf.random_normal([NUM_LABELS],stddev=0), name = 'b_fc6')\n",
    "\n",
    "\n",
    "pred=tf.matmul(h_fc5, W_fc6) + b_fc6\n",
    "\n",
    "y=tf.nn.softmax(pred, name=\"prob_y\")\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "#save weight\n",
    "saver = tf.train.Saver()\n",
    "argmax=tf.argmax(y, 1,name=\"argmax\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session started!\n",
      "close\n"
     ]
    }
   ],
   "source": [
    "print(\"Session started!\")\n",
    "\n",
    "# initialization\n",
    "init_op = tf.group(tf.global_variables_initializer())\n",
    "\n",
    "sess = tf.Session() \n",
    "sess.run(init_op)\n",
    "tf.train.write_graph(sess.graph_def, 'models/', 'graph.pb',as_text=False)\n",
    "sess.close()\n",
    "print(\"close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
